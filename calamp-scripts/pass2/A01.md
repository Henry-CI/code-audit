# Pass 2 Test Coverage — Agent A01
**Files:** .gitignore, README.md
**Branch:** main
**Date:** 2026-02-27

---

## Reading Evidence

---

FILE: `C:/Projects/cig-audit/repos/calamp-scripts/.gitignore`
**Type:** Git ignore configuration file
**Sections/entries:**
- Node artifact files (`node_modules/`, `dist/`)
- Compiled Java class files (`*.class`)
- Compiled Python bytecode (`*.py[cod]`)
- Log files (`*.log`)
- Package files (`*.jar`)
- Maven (`target/`, `dist/`)
- JetBrains IDE (`.idea/`)
- Unit test reports (`TEST*.xml`)
- MacOS artifacts (`.DS_Store`)
- Windows artifacts (`Thumbs.db`)
- Application binaries (`*.app`, `*.exe`, `*.war`)
- Large media files (`*.mp4`, `*.tiff`, `*.avi`, `*.flv`, `*.mov`, `*.wmv`)

**References to testing, validation, or CI:** The entry `TEST*.xml` (line 30) is labelled "Unit test reports" — this is a template-boilerplate pattern for Java/Maven test output files (e.g., JUnit Surefire `TEST-*.xml`). It is not a reference to any actual test infrastructure present in this repository.

**References to approval or review process:** none

**Notes:** The .gitignore is an unmodified Bitbucket/Atlassian template. It was never customised for this repository's actual content (CSV scripts, XML toolbox configs). Entries covering Java, Maven, Node, Python, and binary executables are entirely irrelevant to a CalAmp LMU configuration script repository. There is no entry for `.csv` temp files, LMU Manager workspace files, or any tooling that would indicate test artifacts actually being generated.

---

FILE: `C:/Projects/cig-audit/repos/calamp-scripts/README.md`
**Type:** Repository documentation file
**Sections/entries:**
- "What is this repository for?" — describes it as containing CalAmp LMU scripts for Rayven CI transfer, divided by country/SIM type.
- "How do I get set up?" — instructs users to obtain the `CALAMP APPS/LMU Manager` folder, open CSV files with LMU Manager, and register new scripts with a version name in the "registers."
- "Who do I talk to?" — names one individual contact (Rhythm Duwadi) for new scripts or changes.

**References to testing, validation, or CI:** none

**References to approval or review process:** none. The section "How do I get set up?" mentions that new scripts "should be register in the 'registers'" but does not define what "registers" means, where they exist, or who approves entries. There is no mention of validation against a test device, staging server, UAT environment, peer review, or change-control process.

---

## Test Infrastructure Search Results

### Command: find CI/automation files (*.yml, *.yaml, *.sh, *.ps1, *.bat, Makefile)
```
(no output — zero matching files found)
```

### Command: find test/spec/validate directories
```
(no output — zero matching directories found)
```

### Command: ls repo root
```
8bit Script
Aus Script
CALAMP APPS
Demo Script
README.md
UK Script
URL & PORTS.xlsx
US Script
audit
```

### Full file inventory (non-git, non-audit)
```
.gitignore
8bit Script/50.131-RHM-8bit-LMU1220-POD-10minSleep6hr-Input1POS-PwrMonEvt-PEG0MotionEvtAcc4Dist500Thes10 (1).csv
8bit Script/50.131-RHM-8bit-LMU1220-POD-10minSleep6hr-Input1POS-PwrMonEvt-PEG0MotionEvtAcc4Dist500Thes10.csv
Aus Script/61.61 General for CI old dashboard datamono.csv
Aus Script/Boaroo/69.005 Rayven Boaroo Telstra Final.csv
Aus Script/CEA/50.131 LMU1220 units.csv
Aus Script/CEA/50.132 LMU1220 Rayven.csv
Aus Script/CEA/61.140 Rayven and CI clone CEA Telsta Final.csv
Aus Script/CEA/61.141 Rayven and CI clone CEA data Mono Final.csv
Aus Script/CEA/69.003 RD CEA Telstra Final.csv
Aus Script/CEA/69.004 RD CEA Monogoto Final.csv
Aus Script/DPWorld/61.36 CI DPWORLD Telstra Final.csv
Aus Script/DPWorld/61.37 CI DPWORLD Data.mono Final.csv
Aus Script/Keller/61.101 Rayven Keller Demo Blank APN.csv
Aus Script/Keller/61.111 Optimal Script for Keller.csv
Aus Script/Komatsu_AU/61.133 Rayven and CI clone Komatsu Telstra Final.csv
Aus Script/Komatsu_AU/61.135 Rayven and CI clone Komatsu Data.mono Final.csv
Aus Script/Komatsu_AU/69.001 RD Komatsu Telstra Final.csv
Aus Script/Komatsu_AU/69.002 RD Komatsu Monogoto Final.csv
CALAMP APPS/AppendCRC16ToBin/x.bin
CALAMP APPS/LMUMgr_8.9.10.7.zip
CALAMP APPS/LMUToolbox_V41/ConfigParams.xml
CALAMP APPS/LMUToolbox_V41/PEG List.xml
CALAMP APPS/LMUToolbox_V41/VBUS.xml
Demo Script/61.142 Demo Rayven datamono.csv
README.md
UK Script/161.31 CI only Data.Mono Final.csv
UK Script/161.32 Rayven Demo DataMono Final.csv
URL & PORTS.xlsx
US Script/Matthai/61.137 Rayven and CI clone Matthai DataMono.csv
US Script/Matthai/61.138 Rayven Matthai DataMono.csv
US Script/Matthai/61.139 Rayven Mathhai Kore.csv
US Script/PAPE/62.134 Rayven CI PAPE Final Datamono.csv
US Script/PAPE/62.137 Rayven CI PAPE Final Pod.csv
US Script/PAPE/62.200 Rayven PAPE Final Datamono Fixed.csv
US Script/PAPE/62.371 Rayven PAPE Final Pod Fixed.csv
US Script/PAPE/63.137 Rayven PAPE Final Pod Fixed.csv
US Script/SIE/69.006 Rayven SIE Datamono Final.csv
```

---

## Findings

**A01-1** — CRITICAL: No CI/CD pipeline or automated validation exists
**Description:** There are zero CI/CD configuration files in the repository (no `.yml`, `.yaml`, `.sh`, `.ps1`, `.bat`, or `Makefile`). No automated schema validation, linting, or structural checks are applied to any CSV script at commit time or on push. Every script is committed and made available for deployment to physical LMU devices with no automated gate of any kind. A malformed, misconfigured, or malicious CSV could be deployed to hardware with no automated detection.
**Fix:** Introduce a CI pipeline (e.g., GitHub Actions or Bitbucket Pipelines) with at minimum: (1) a CSV schema validator that checks required columns and value ranges against the LMU parameter specification, (2) a diff-based review step that highlights changes to critical fields such as server IP/hostname, port, APN, and reporting intervals before any script is merged to main.

---

**A01-2** — CRITICAL: README.md contains no validation or pre-deployment testing process
**Description:** The README.md documents only how to open a script file with LMU Manager and a single-person escalation path. It contains no description of how a script is validated before being uploaded to a real device: no mention of a test device, staging server, bench test, UAT environment, peer review, or sign-off process. The phrase "should be register in the 'registers'" is undefined and unlinked. As written, the process is: edit CSV in LMU Manager, commit to main, deploy to devices.
**Fix:** Add a "Validation and Deployment" section to README.md documenting: (1) the mandatory steps before a script is uploaded to production hardware (e.g., bench test on a lab device, smoke test against a staging Rayven server), (2) who must review and approve a script change before it is merged, (3) what the "registers" are and where they live, (4) the procedure for rolling back a bad script.

---

**A01-3** — HIGH: .gitignore is an unmodified generic template — not customised for this repository
**Description:** The .gitignore is a verbatim Atlassian/Bitbucket boilerplate template covering Java, Maven, Node, Python, and binary artifacts — none of which are relevant to a CSV/XML LMU configuration repository. It has never been updated for this project's actual artifact types. Critically, it does not ignore LMU Manager workspace or temp files, which means local tool artifacts could be accidentally committed. The entry `TEST*.xml` labelled "Unit test reports" is boilerplate for JUnit output, not evidence of any real test tooling.
**Fix:** Replace the .gitignore with one appropriate to the repository's actual content. At minimum: ignore LMU Manager temporary files and any working-copy artifacts produced by the toolbox. Remove all Java/Maven/Node/Python entries. If any test harness is introduced, add entries for its output artifacts at that time.

---

**A01-4** — HIGH: No test or staging variants exist for the majority of production scripts
**Description:** Of approximately 30 production CSV scripts across AU, UK, and US regions, only two scripts are explicitly labelled as "Demo" (`61.101 Rayven Keller Demo Blank APN.csv`, `61.142 Demo Rayven datamono.csv`, `161.32 Rayven Demo DataMono Final.csv`) and these are isolated to specific customers or country folders rather than being systematic test counterparts to production scripts. There are no scripts labelled "test", "staging", or "bench" for any customer. Most production scripts have no corresponding safe/sandboxed version that could be applied to a test device before the production configuration is deployed.
**Fix:** For each production customer script, maintain a corresponding test-environment variant that points to a non-production Rayven server/port and uses a test APN. Establish a naming convention (e.g., suffix `-TEST` or `-STAGING`) and a dedicated directory so test variants are clearly distinguished from production scripts in the repository.

---

**A01-5** — HIGH: Single point of failure in process — one named contact for all script changes
**Description:** README.md identifies a single individual ("Rhythm Duwadi") as the sole contact for any new scripts or changes. There is no documented backup, team, or committee. This means there is no enforced peer-review or second-pair-of-eyes requirement for changes to scripts that are directly applied to GPS hardware on customer sites.
**Fix:** Document a minimum two-person review requirement for any script change merged to main. Implement branch protection on the `main` branch requiring at least one approving review before merge. Name at least one secondary reviewer or team in the README.

---

**A01-6** — MEDIUM: No documentation of edge-case or error-condition script coverage
**Description:** There is one notable edge-case script: `61.101 Rayven Keller Demo Blank APN.csv` (blank APN behaviour). However, there is no systematic documentation of what edge conditions the script set covers or is intended to cover. There is no indication that scripts testing fallback server behaviour, connection retry logic, power-loss recovery, or invalid parameter handling have been created or are considered necessary.
**Fix:** Add a test coverage matrix to the repository (or to README.md) listing known edge conditions (blank APN, fallback server, sleep/wake cycle boundary, input debounce, power monitor event threshold) and which script(s) — production or test — cover each condition. Identify gaps and create dedicated edge-case test scripts for any gaps.

---

**A01-7** — MEDIUM: "Registers" reference in README is undefined and unverifiable
**Description:** README.md instructs that new scripts "should be register in the 'registers'" but provides no link, file path, system name, or definition for what the registers are. It is impossible to verify whether this step is followed, who maintains it, or whether it constitutes any form of change control. The registers do not appear to exist within this repository.
**Fix:** Define the registers explicitly in README.md: what they are, where they are maintained (e.g., a specific spreadsheet, Jira project, Confluence page), and who is responsible for updating them. If the register is a file, move it into the repository so it is versioned alongside the scripts it tracks.

---

**A01-8** — LOW: Duplicate script file present in repository (copy-with-space-in-name)
**Description:** The `8bit Script/` directory contains two files with identical base names differing only by ` (1)` suffix (`50.131-RHM-8bit-LMU1220-...csv` and `50.131-RHM-8bit-LMU1220-... (1).csv`). This pattern is characteristic of an OS-generated duplicate from a drag-and-drop copy operation. It is unclear whether these are intentionally different versions or an accidental duplicate. If the `(1)` copy is being used instead of the original, the wrong configuration could be applied to devices.
**Fix:** Confirm which file is canonical, remove the duplicate, and adopt a version-numbering convention in script names (already partially in place via the numeric prefix scheme) so that version lineage is unambiguous.

---

**A01-9** — LOW: URL & PORTS.xlsx is a binary reference document with no version history
**Description:** `URL & PORTS.xlsx` is a binary Excel file commited to the repository. It presumably documents server endpoints and port numbers that are also embedded in the CSV scripts. Binary files are not diffable, so changes to server addresses or ports in this reference document cannot be reviewed as plain text. There is no mechanism to verify that the Excel content matches the values actually configured in the deployed scripts.
**Fix:** Convert `URL & PORTS.xlsx` to a plain-text format (e.g., Markdown table or CSV) so that changes are reviewable in pull requests. Add a CI check or manual checklist step that cross-references the documented endpoints against the values found in production script files.

---

*End of A01 findings. Total findings: 9 (2 CRITICAL, 3 HIGH, 2 MEDIUM, 2 LOW).*
